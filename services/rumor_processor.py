from services.text_rewriter_enhanced import TextRewriter
from config.database import get_db_connection
import time
import psycopg2
import re
import os

class RumorProcessor:
    def __init__(self, use_trained_model=False):
        """
        Kh·ªüi t·∫°o RumorProcessor
        
        Args:
            use_trained_model (bool): N·∫øu True, s·ª≠ d·ª•ng model ƒë√£ hu·∫•n luy·ªán
        """
        self.use_trained_model = use_trained_model
        self.text_rewriter = None
        self._initialize_rewriter()
        
    def _initialize_rewriter(self):
        """Kh·ªüi t·∫°o text rewriter v·ªõi model ph√π h·ª£p"""
        try:
            if self.use_trained_model:
                print("üîÑ Initializing with TRAINED rewriter model...")
                # S·ª≠ d·ª•ng model ƒë√£ hu·∫•n luy·ªán
                trained_model_path = "./trained_rewriter_model"
                
                if os.path.exists(trained_model_path):
                    self.text_rewriter = TextRewriter(trained_model_path)
                    print("‚úÖ Trained rewriter model loaded successfully!")
                else:
                    print("‚ö†Ô∏è Trained model not found, using base model instead")
                    self.text_rewriter = TextRewriter()
            else:
                print("üîÑ Initializing with BASE rewriter model...")
                # S·ª≠ d·ª•ng model g·ªëc
                self.text_rewriter = TextRewriter()
                
        except Exception as e:
            print(f"‚ùå Error initializing text rewriter: {e}")
            # Fallback to base model
            self.text_rewriter = TextRewriter()
    
    def process_rumors_batch(self, batch_size=50, last_24h_only=False):
        """
        X·ª≠ l√Ω m·ªôt batch d·ªØ li·ªáu t·ª´ b·∫£ng rumor v√† chuy·ªÉn sang rumor_analyst
        Ch·ªâ vi·∫øt l·∫°i n·ªôi dung, gi·ªØ nguy√™n sentiment v√† symbol
        """
        conn = get_db_connection()
        cur = conn.cursor()
        
        try:
            # X√¢y d·ª±ng query d·ª±a tr√™n th·ªùi gian
            if last_24h_only:
                current_timestamp = int(time.time())
                twenty_four_hours_ago = current_timestamp - (24 * 60 * 60)
                
                cur.execute("""
                    SELECT r.id, r.timestamp, r.symbol, r.content, r.sentiment, r.source
                    FROM rumor r
                    WHERE NOT EXISTS (
                        SELECT 1 FROM rumor_analyst ra WHERE ra.processed_from_rumor_id = r.id
                    )
                    AND r.timestamp >= %s
                    ORDER BY r.timestamp DESC
                    LIMIT %s
                """, (twenty_four_hours_ago, batch_size))
            else:
                cur.execute("""
                    SELECT r.id, r.timestamp, r.symbol, r.content, r.sentiment, r.source
                    FROM rumor r
                    WHERE NOT EXISTS (
                        SELECT 1 FROM rumor_analyst ra WHERE ra.processed_from_rumor_id = r.id
                    )
                    ORDER BY r.timestamp DESC
                    LIMIT %s
                """, (batch_size,))
            
            rumors = cur.fetchall()
            
            if not rumors:
                time_constraint = " from last 24 hours" if last_24h_only else ""
                model_type = "TRAINED" if self.use_trained_model else "BASE"
                print(f"No rumors{time_constraint} to process with {model_type} model.")
                return 0
            
            processed_count = 0
            error_count = 0
            
            for rumor_id, timestamp, symbol, content, sentiment, source in rumors:
                try:
                    model_type = "TRAINED" if self.use_trained_model else "BASE"
                    print(f"\n--- Processing rumor {rumor_id} ({model_type} model) ---")
                    print(f"Original: {content}")
                    
                    # Ki·ªÉm tra d·ªØ li·ªáu ƒë·∫ßu v√†o
                    if not content or len(str(content).strip()) < 3:
                        print(f"Skipping rumor {rumor_id}: content too short")
                        continue
                    
                    # B∆∞·ªõc duy nh·∫•t: Vi·∫øt l·∫°i n·ªôi dung
                    rewritten_content = self.text_rewriter.rewrite_rumor_text(str(content))
                    
                    # Ki·ªÉm tra k·∫øt qu·∫£ vi·∫øt l·∫°i
                    if not rewritten_content or len(rewritten_content.strip()) < 3:
                        print(f"Rewritten content too short for rumor {rumor_id}, using original")
                        rewritten_content = str(content)
                    
                    print(f"Rewritten: {rewritten_content}")
                    
                    # X·ª≠ l√Ω symbol ƒë·ªÉ tr√°nh l·ªói ƒë·ªô d√†i
                    safe_symbol = self._validate_symbol(symbol)
                    
                    # Chu·∫©n b·ªã d·ªØ li·ªáu ƒë·ªÉ insert
                    insert_data = (
                        str(content)[:1000],  # original_content (gi·ªõi h·∫°n ƒë·ªô d√†i)
                        str(rewritten_content)[:1000],  # rewritten_content (gi·ªõi h·∫°n ƒë·ªô d√†i)
                        safe_symbol,  # symbol (ƒë√£ ƒë∆∞·ª£c validate)
                        sentiment,  # sentiment (c√≥ th·ªÉ l√† None)
                        source,  # source (c√≥ th·ªÉ l√† None)
                        timestamp,  # timestamp
                        rumor_id  # processed_from_rumor_id
                    )
                    
                    # Th·ª±c hi·ªán insert
                    cur.execute("""
                        INSERT INTO rumor_analyst 
                        (original_content, rewritten_content, symbol, sentiment, source, timestamp, processed_from_rumor_id)
                        VALUES (%s, %s, %s, %s, %s, %s, %s)
                    """, insert_data)
                    
                    processed_count += 1
                    print(f"‚úì Processed rumor {rumor_id}")
                    
                    # Commit th∆∞·ªùng xuy√™n h∆°n ƒë·ªÉ tr√°nh transaction d√†i
                    if processed_count % 5 == 0:
                        conn.commit()
                        print(f"Committed {processed_count} rumors")
                
                except psycopg2.Error as e:
                    error_count += 1
                    print(f"‚úó Database error processing rumor {rumor_id}: {e}")
                    # Rollback transaction hi·ªán t·∫°i v√† ti·∫øp t·ª•c
                    conn.rollback()
                    continue
                    
                except Exception as e:
                    error_count += 1
                    print(f"‚úó General error processing rumor {rumor_id}: {e}")
                    # Rollback transaction hi·ªán t·∫°i v√† ti·∫øp t·ª•c
                    conn.rollback()
                    continue
            
            # Commit c√°c b·∫£n ghi c√≤n l·∫°i
            if processed_count > 0:
                conn.commit()
                model_type = "TRAINED" if self.use_trained_model else "BASE"
                print(f"‚úÖ Successfully processed {processed_count} rumors with {model_type} model")
            
            if error_count > 0:
                print(f"‚ö†Ô∏è  Encountered {error_count} errors during processing")
                
            return processed_count
            
        except Exception as e:
            print(f"‚ùå Error processing rumors batch: {e}")
            conn.rollback()
            return 0
        finally:
            cur.close()
            conn.close()
    
    def _validate_symbol(self, symbol):
        """Validate v√† l√†m s·∫°ch symbol ƒë·ªÉ tr√°nh l·ªói database"""
        if not symbol:
            return None
        
        symbol_str = str(symbol).strip().upper()
        
        # Gi·ªõi h·∫°n ƒë·ªô d√†i symbol (th∆∞·ªùng m√£ ch·ª©ng kho√°n VN <= 10 k√Ω t·ª±)
        if len(symbol_str) > 10:
            # C·∫Øt b·ªõt n·∫øu qu√° d√†i, nh∆∞ng ∆∞u ti√™n gi·ªØ ph·∫ßn ƒë·∫ßu
            symbol_str = symbol_str[:10]
            print(f"Warning: Symbol truncated to {symbol_str}")
        
        # Lo·∫°i b·ªè k√Ω t·ª± kh√¥ng h·ª£p l·ªá
        symbol_str = re.sub(r'[^A-Z0-9]', '', symbol_str)
        
        return symbol_str if symbol_str else None
    
    def get_processing_stats(self):
        """L·∫•y th·ªëng k√™ v·ªÅ d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω"""
        conn = get_db_connection()
        cur = conn.cursor()
        
        try:
            cur.execute("SELECT COUNT(*) FROM rumor")
            total_rumors = cur.fetchone()[0]
            
            cur.execute("SELECT COUNT(DISTINCT processed_from_rumor_id) FROM rumor_analyst")
            processed_rumors = cur.fetchone()[0]
            
            return {
                'total_rumors': total_rumors,
                'processed_rumors': processed_rumors,
                'processing_rate': (processed_rumors / total_rumors * 100) if total_rumors > 0 else 0
            }
            
        except Exception as e:
            print(f"Error getting processing stats: {e}")
            return {}
        finally:
            cur.close()
            conn.close()